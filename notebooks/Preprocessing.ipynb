{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "425d2180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import Dataset,DataLoader,TensorDataset\n",
    "import torch \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b23e26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: nvidia: command not found\n"
     ]
    }
   ],
   "source": [
    "! nvidia -smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11a30a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# Data Preprocessing\n",
    "# ==============================\n",
    "class DataPreprocessing:\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df.copy()\n",
    "        self.scaler = MinMaxScaler()\n",
    "        self.feature_names = list(df.columns)\n",
    "\n",
    "    def normalize(self) -> pd.DataFrame:\n",
    "        arr = self.scaler.fit_transform(self.df.values)\n",
    "        return pd.DataFrame(arr, index=self.df.index, columns=self.df.columns)\n",
    "\n",
    "    def inverse_target(self, arr: np.ndarray, target_cols) -> np.ndarray:\n",
    "      \"\"\"\n",
    "      Inverse transform multiple target columns.\n",
    "\n",
    "      arr : shape (N, horizon) or (N, len(target_cols))\n",
    "      target_cols : list of strings of target variable names\n",
    "      \"\"\"\n",
    "      arr = np.array(arr)\n",
    "\n",
    "      # Ensure 2D\n",
    "      if arr.ndim == 1:\n",
    "          arr = arr.reshape(-1, 1)\n",
    "\n",
    "      # If arr has 1 column but multiple targets requested â†’ ERROR CHECK\n",
    "      if arr.shape[1] != len(target_cols):\n",
    "          raise ValueError(\n",
    "              f\"Shape mismatch: arr has {arr.shape[1]} columns, \"\n",
    "              f\"but target_cols has {len(target_cols)} targets. \"\n",
    "              f\"Expected arr.shape = (N, {len(target_cols)}).\"\n",
    "          )\n",
    "\n",
    "      inv_arr = np.zeros((arr.shape[0], len(target_cols)))\n",
    "\n",
    "      for i, col in enumerate(target_cols):\n",
    "          target_idx = self.feature_names.index(col)\n",
    "\n",
    "          # build dummy vector\n",
    "          dummy = np.zeros((arr.shape[0], len(self.feature_names)))\n",
    "          dummy[:, target_idx] = arr[:, i]\n",
    "\n",
    "          # inverse scale\n",
    "          inv = self.scaler.inverse_transform(dummy)\n",
    "          inv_arr[:, i] = inv[:, target_idx]\n",
    "\n",
    "      return inv_arr\n",
    "\n",
    "\n",
    "    def create_windows(self, df, target_cols, lag, horizon=1):\n",
    "        data = df.values\n",
    "        target_idx = [df.columns.get_loc(col) for col in target_cols]\n",
    "\n",
    "        X = []\n",
    "        Y = []\n",
    "\n",
    "        for i in range(len(df) - lag - horizon + 1):\n",
    "            X.append(data[i:i+lag, :])                    # shape (lag, features)\n",
    "            Y.append(data[i+lag:i+lag+horizon, target_idx])  # shape (horizon, targets)\n",
    "\n",
    "        return np.array(X), np.array(Y)\n",
    "\n",
    "\n",
    "\n",
    "    def to_dataloader(self, X_train, Y_train, X_test, Y_test, batch_size=64):\n",
    "        if Y_train.ndim == 1:\n",
    "            Y_train = Y_train.reshape(-1, 1)\n",
    "        if Y_test.ndim == 1:\n",
    "            Y_test = Y_test.reshape(-1, 1)\n",
    "        train_loader = DataLoader(\n",
    "            TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(Y_train).float()),\n",
    "            batch_size=batch_size, shuffle=True\n",
    "        )\n",
    "        test_loader = DataLoader(\n",
    "            TensorDataset(torch.from_numpy(X_test).float(), torch.from_numpy(Y_test).float()),\n",
    "            batch_size=batch_size, shuffle=False\n",
    "        )\n",
    "        return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b05a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
